name: "mistralai/Mistral-7B-v0.1" #"meta-llama/Llama-2-7b-hf" #pt2  # google/flan-t5-base
provider: "hf"
type: "causal_lm"
device: "auto"
max_gen_toks: 512
padding_side: "left"
tokenizer_name: "mistralai/Mistral-7B-v0.1"  #"meta-llama/Llama-2-7b-hf"  # gpt2-xl # google/flan-t5-base
generation_args:
        do_sample: True
        top_p: 0.95
        temperature: 0.2

