name: "mistralai/Mistral-7B-Instruct-v0.1" # "meta-llama/Llama-2-7b-hf" #pt2  # google/flan-t5-base
provider: "hf"
type: "causal_lm"
device: "auto"
max_gen_toks: 4048
padding_side: "left"
batch_size: 1
tokenizer_name: "mistralai/Mistral-7B-Instruct-v0.1" # "meta-llama/Llama-2-7b-hf"  # gpt2-xl # google/flan-t5-base
generation_args:
  do_sample: True

