config:
  run_id: 1
  model:
    name: EleutherAI/gpt-neo-125m  # google/flan-t5-base
    provider: "hf"
    type: "causal_lm"
    device: "cpu"
    batch_size: 4
    tokenizer_name: EleutherAI/gpt-neo-125m # google/flan-t5-base
    dtype: "float32"
    padding_side: "left"
    template: "Question: {{input}}\n\nAnswer: "
    generation_args:
      num_beams: 2
      do_sample: true
      top_k: 25
      temperature: 2.0
  seed: 36
  benchmark_configs:
    - name: "llm_rules"
      type: "multiple_choice"
      provider: "hf"
      data_url: hellaswag
      debug: 
        sample_size: 1
      splits:
        - test
      k_shot: 3
      k_shot_split: validation
      mapping_config:
        input: "question"
        choices: "choices"
        labels: "answer"
        template: "{{input}}\n\nA:{{choices[0]}} \nB:{{choices[1]}} \nC:{{choices[2]}} \nD:{{choices[3]}}"
      label_mapping:
        A: 0 
        B: 1
        C: 2
        D: 3
      data_dir: "mmlu-dir"
      checking_mode: "label"
      num_workers: 1
      modifier_configs:
        - name: writing_mistakes
          provider: "nlp"
          params:
            aug_char_p: 1.0
            aug_char_min: 50
            aug_char_max: 200
      metric_configs:
        - name: "accuracy"
