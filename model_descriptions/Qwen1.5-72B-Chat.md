# Metadata

## model_name
<!--- Name of the model -->
Qwen1.5 72B Chat

## model_num_parameters
<!--- Number of Parameters -->
72B

## model_creator
<!--- Creator of the model -->
Qwen / Alibaba Cloud

## model_version
<!--- Used model version -->
Qwen/Qwen1.5-72B-Chat

## model_published
<!--- When was the model published -->
February 2024

## model_type
<!--- {api, api_with_logit, local} -->
local

## model_link
<!--- Link to the model -->
https://huggingface.co/Qwen/Qwen1.5-72B-Chat

## model_description
<!--- Short description of the model -->
Qwen1.5 is a language model series including decoder language models of different model sizes. It is the publicly-available beta for Qwen2. Qwen1.5 is based on the Transformer architecture with SwiGLU activation, attention QKV bias, group query attention, mixture of sliding window attention and full attention, etc. The 72B model is the largest model in the Qwen1.5 family.

# environment

## num_gpus
<!--- number of gpu's used --> 
-

## gpu_power_draw
<!--- draw of the used GPUs in kW --> 
-

## time_to_train
<!--- total time taken for training in hours --> 
-

## datacenter_carbon_intensity
<!--- grams of CO2 emissions per kWh of energy consumed of the datacenter -->
-